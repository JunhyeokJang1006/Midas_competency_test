%% ì¸ì¬ìœ í˜• ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ v3.0 (Enhanced Class Imbalance Solution)
% HR Talent Type Comprehensive Analysis System
% ëª©ì : 1) ì¸ì¬ ìœ í˜•ë³„ í”„ë¡œíŒŒì¼ë§
%      2) ìƒê´€ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë¶€ì—¬
%      3) ê³ ë„í™”ëœ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì„ ì´ìš©í•œ ì˜ˆì¸¡ ë¶„ì„ (í´ë˜ìŠ¤ ë¶ˆê· í˜• ìµœì í™”)

clear; clc; close all;

%% ========================================================================
%                          PART 1: ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
% =========================================================================

fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
fprintf('         ì¸ì¬ìœ í˜• ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ v3.0 (Enhanced)\n');
fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

% ì „ì—­ ì„¤ì •
set(0, 'DefaultAxesFontName', 'Malgun Gothic');
set(0, 'DefaultTextFontName', 'Malgun Gothic');
set(0, 'DefaultAxesFontSize', 11);
set(0, 'DefaultTextFontSize', 11);
set(0, 'DefaultLineLineWidth', 1.5);

% íŒŒì¼ ê²½ë¡œ ì„¤ì •
config = struct();
config.hr_file = 'D:\project\HRë°ì´í„°\ë°ì´í„°\ì—­ëŸ‰ê²€ì‚¬ ìš”ì²­ ì •ë³´\ìµœê·¼ 3ë…„ ì…ì‚¬ì_ì¸ì ì •ë³´.xlsx';
config.comp_file = 'D:\project\HRë°ì´í„°\ë°ì´í„°\ì—­ëŸ‰ê²€ì‚¬ ìš”ì²­ ì •ë³´\23-25ë…„ ì—­ëŸ‰ê²€ì‚¬.xlsx';
config.output_dir = pwd;

% ì„±ê³¼ ìˆœìœ„ ì •ì˜ (ì‚¬ìš©ì ì œê³µ)
config.performance_ranking = containers.Map(...
    {'ìì—°ì„±', 'ì„±ì‹¤í•œ ê°€ì—°ì„±', 'ìœ ìµí•œ ë¶ˆì—°ì„±', 'ìœ ëŠ¥í•œ ë¶ˆì—°ì„±', ...
     'ê²Œìœ¼ë¥¸ ê°€ì—°ì„±', 'ë¬´ëŠ¥í•œ ë¶ˆì—°ì„±', 'ìœ„ì¥í˜• ì†Œí™”ì„±', 'ì†Œí™”ì„±'}, ...
    [8, 7, 6, 5, 4, 3, 2, 1]);

%% 1.1 ë°ì´í„° ë¡œë”©
fprintf('ã€STEP 1ã€‘ ë°ì´í„° ë¡œë”©\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

try
    % HR ë°ì´í„° ë¡œë”©
    fprintf('â–¶ HR ë°ì´í„° ë¡œë”© ì¤‘...\n');
    hr_data = readtable(config.hr_file, 'Sheet', 1, 'VariableNamingRule', 'preserve');
    fprintf('  âœ“ HR ë°ì´í„°: %dëª… ë¡œë“œ ì™„ë£Œ\n', height(hr_data));

    % ì—­ëŸ‰ê²€ì‚¬ ë°ì´í„° ë¡œë”©
    fprintf('â–¶ ì—­ëŸ‰ê²€ì‚¬ ë°ì´í„° ë¡œë”© ì¤‘...\n');
    comp_upper = readtable(config.comp_file, 'Sheet', 'ì—­ëŸ‰ê²€ì‚¬_ìƒìœ„í•­ëª©', 'VariableNamingRule', 'preserve');
    comp_total = readtable(config.comp_file, 'Sheet', 'ì—­ëŸ‰ê²€ì‚¬_ì¢…í•©ì ìˆ˜', 'VariableNamingRule', 'preserve');
    fprintf('  âœ“ ìƒìœ„í•­ëª© ë°ì´í„°: %dëª…\n', height(comp_upper));
    fprintf('  âœ“ ì¢…í•©ì ìˆ˜ ë°ì´í„°: %dëª…\n', height(comp_total));

catch ME
    error('ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: %s', ME.message);
end

%% 1.2 ì¸ì¬ìœ í˜• ë°ì´í„° ì¶”ì¶œ
fprintf('\nã€STEP 2ã€‘ ì¸ì¬ìœ í˜• ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ì¸ì¬ìœ í˜• ì»¬ëŸ¼ ì°¾ê¸°
talent_col_idx = find(contains(hr_data.Properties.VariableNames, {'ì¸ì¬ìœ í˜•', 'ì¸ì¬', 'ìœ í˜•'}), 1);
if isempty(talent_col_idx)
    error('ì¸ì¬ìœ í˜• ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
end

talent_col_name = hr_data.Properties.VariableNames{talent_col_idx};
fprintf('â–¶ ì¸ì¬ìœ í˜• ì»¬ëŸ¼: %s\n', talent_col_name);

% ë¹ˆ ê°’ ì œê±°
hr_clean = hr_data(~cellfun(@isempty, hr_data{:, talent_col_idx}), :);
fprintf('â–¶ ìœ íš¨í•œ ì¸ì¬ìœ í˜• ë°ì´í„°: %dëª…\n', height(hr_clean));

% ì¸ì¬ìœ í˜• ë¶„í¬ ë¶„ì„
talent_types = hr_clean{:, talent_col_idx};
[unique_types, ~, type_indices] = unique(talent_types);
type_counts = accumarray(type_indices, 1);

fprintf('\nì¸ì¬ìœ í˜• ë¶„í¬:\n');
for i = 1:length(unique_types)
    fprintf('  â€¢ %-20s: %3dëª… (%5.1f%%)\n', ...
        unique_types{i}, type_counts(i), type_counts(i)/sum(type_counts)*100);
end

%% 1.3 ì—­ëŸ‰ ë°ì´í„° ì²˜ë¦¬
fprintf('\nã€STEP 3ã€‘ ì—­ëŸ‰ ë°ì´í„° ì²˜ë¦¬\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ID ì»¬ëŸ¼ ì°¾ê¸°
comp_id_col = find(contains(lower(comp_upper.Properties.VariableNames), {'id', 'ì‚¬ë²ˆ'}), 1);
if isempty(comp_id_col)
    error('ì—­ëŸ‰ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
end

fprintf('â–¶ ì—­ëŸ‰ ID ì»¬ëŸ¼: %s\n', comp_upper.Properties.VariableNames{comp_id_col});

% ìœ íš¨í•œ ì—­ëŸ‰ ì»¬ëŸ¼ ì¶”ì¶œ (ìˆ«ìí˜•ì´ê³  ë³€ë™ì„±ì´ ìˆëŠ” ì»¬ëŸ¼)
valid_comp_cols = {};
valid_comp_indices = [];

for i = 6:width(comp_upper)  % ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ ì œì™¸
    col_data = comp_upper{:, i};
    if isnumeric(col_data) && ~all(isnan(col_data))
        valid_data = col_data(~isnan(col_data));
        if length(valid_data) >= 5 && var(valid_data) > 0 && ...
           all(valid_data >= 0) && all(valid_data <= 100)
            valid_comp_cols{end+1} = comp_upper.Properties.VariableNames{i};
            valid_comp_indices(end+1) = i;
        end
    end
end

fprintf('â–¶ ìœ íš¨í•œ ì—­ëŸ‰ í•­ëª©: %dê°œ\n', length(valid_comp_cols));
fprintf('  ì—­ëŸ‰ ëª©ë¡:\n');
for i = 1:min(5, length(valid_comp_cols))
    fprintf('    %d. %s\n', i, valid_comp_cols{i});
end
if length(valid_comp_cols) > 5
    fprintf('    ... ì™¸ %dê°œ\n', length(valid_comp_cols)-5);
end

%% 1.4 ID ë§¤ì¹­ ë° ë°ì´í„° í†µí•©
fprintf('\nã€STEP 4ã€‘ ë°ì´í„° ë§¤ì¹­ ë° í†µí•©\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ID í‘œì¤€í™”
hr_ids_str = arrayfun(@(x) sprintf('%.0f', x), hr_clean.ID, 'UniformOutput', false);
comp_ids_str = arrayfun(@(x) sprintf('%.0f', x), comp_upper{:, comp_id_col}, 'UniformOutput', false);

% êµì§‘í•© ì°¾ê¸°
[matched_ids, hr_idx, comp_idx] = intersect(hr_ids_str, comp_ids_str);

if length(matched_ids) < 10
    error('ë§¤ì¹­ëœ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: %dëª…', length(matched_ids));
end

fprintf('â–¶ ë§¤ì¹­ ì„±ê³µ: %dëª…\n', length(matched_ids));

% ë§¤ì¹­ëœ ë°ì´í„° ì¶”ì¶œ
matched_hr = hr_clean(hr_idx, :);
matched_comp = comp_upper(comp_idx, valid_comp_indices);
matched_talent_types = matched_hr{:, talent_col_idx};

% ì¢…í•©ì ìˆ˜ ë§¤ì¹­
comp_total_ids_str = arrayfun(@(x) sprintf('%.0f', x), comp_total{:, 1}, 'UniformOutput', false);
[~, ~, total_idx] = intersect(matched_ids, comp_total_ids_str);

if ~isempty(total_idx)
    total_scores = comp_total{total_idx, end};
    fprintf('â–¶ ì¢…í•©ì ìˆ˜ í†µí•©: %dëª…\n', length(total_idx));
else
    total_scores = [];
    fprintf('âš  ì¢…í•©ì ìˆ˜ ë°ì´í„° ì—†ìŒ\n');
end

%% ========================================================================
%                    PART 2: ì¸ì¬ìœ í˜•ë³„ í”„ë¡œíŒŒì¼ë§
% =========================================================================

fprintf('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
fprintf('              PART 2: ì¸ì¬ìœ í˜•ë³„ í”„ë¡œíŒŒì¼ë§\n');
fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

%% 2.1 ê¸°ìˆ í†µê³„ ë¶„ì„
fprintf('ã€STEP 5ã€‘ ì¸ì¬ìœ í˜•ë³„ ê¸°ìˆ í†µê³„\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

unique_matched_types = unique(matched_talent_types);
n_types = length(unique_matched_types);

% í†µê³„ í…Œì´ë¸” ì´ˆê¸°í™”
profile_stats = table();
profile_stats.TalentType = unique_matched_types;
profile_stats.Count = zeros(n_types, 1);
profile_stats.CompetencyMean = zeros(n_types, 1);
profile_stats.CompetencyStd = zeros(n_types, 1);
profile_stats.TotalScoreMean = zeros(n_types, 1);
profile_stats.PerformanceRank = zeros(n_types, 1);

% ê° ìœ í˜•ë³„ ì—­ëŸ‰ í”„ë¡œíŒŒì¼ ì €ì¥
type_profiles = cell(n_types, 1);

for i = 1:n_types
    type_name = unique_matched_types{i};
    type_mask = strcmp(matched_talent_types, type_name);

    % ê¸°ë³¸ í†µê³„
    profile_stats.Count(i) = sum(type_mask);

    % ì—­ëŸ‰ ì ìˆ˜ í†µê³„
    type_comp_data = matched_comp{type_mask, :};
    profile_stats.CompetencyMean(i) = nanmean(type_comp_data(:));
    profile_stats.CompetencyStd(i) = nanstd(type_comp_data(:));

    % ì¢…í•©ì ìˆ˜ í†µê³„
    if ~isempty(total_scores)
        type_total_scores = total_scores(type_mask);
        profile_stats.TotalScoreMean(i) = nanmean(type_total_scores);
    end

    % ì„±ê³¼ ìˆœìœ„
    if config.performance_ranking.isKey(type_name)
        profile_stats.PerformanceRank(i) = config.performance_ranking(type_name);
    end

    % ìƒì„¸ í”„ë¡œíŒŒì¼ ì €ì¥
    type_profiles{i} = nanmean(type_comp_data, 1);
end

% ê²°ê³¼ ì¶œë ¥
fprintf('\nì¸ì¬ìœ í˜•ë³„ í†µê³„ ìš”ì•½:\n');
fprintf('%-20s | ì¸ì› | ì—­ëŸ‰í‰ê·  | í‘œì¤€í¸ì°¨ | ì¢…í•©ì ìˆ˜ | ì„±ê³¼ìˆœìœ„\n', 'ìœ í˜•');
fprintf('%s\n', repmat('-', 70, 1));

for i = 1:height(profile_stats)
    fprintf('%-20s | %4d | %8.2f | %8.2f | %8.2f | %8.0f\n', ...
        profile_stats.TalentType{i}, profile_stats.Count(i), ...
        profile_stats.CompetencyMean(i), profile_stats.CompetencyStd(i), ...
        profile_stats.TotalScoreMean(i), profile_stats.PerformanceRank(i));
end

%% ========================================================================
%                    PART 3: ìƒê´€ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë¶„ì„
% =========================================================================

fprintf('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
fprintf('              PART 3: ìƒê´€ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë¶„ì„\n');
fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

%% 3.1 ì„±ê³¼ì ìˆ˜ ê³„ì‚°
fprintf('ã€STEP 6ã€‘ ì„±ê³¼ì ìˆ˜ ê¸°ë°˜ ìƒê´€ë¶„ì„\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ê° ê°œì¸ì˜ ì„±ê³¼ì ìˆ˜ í• ë‹¹
performance_scores = zeros(length(matched_talent_types), 1);
for i = 1:length(matched_talent_types)
    type_name = matched_talent_types{i};
    if config.performance_ranking.isKey(type_name)
        performance_scores(i) = config.performance_ranking(type_name);
    end
end

% ìœ íš¨í•œ ë°ì´í„°ë§Œ ì„ íƒ
valid_perf_idx = performance_scores > 0;
valid_performance = performance_scores(valid_perf_idx);
valid_competencies = table2array(matched_comp(valid_perf_idx, :));

fprintf('â–¶ ì„±ê³¼ì ìˆ˜ í• ë‹¹ ì™„ë£Œ: %dëª…\n', sum(valid_perf_idx));

%% 3.2 ì—­ëŸ‰ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
fprintf('\nã€STEP 7ã€‘ ì—­ëŸ‰-ì„±ê³¼ ìƒê´€ë¶„ì„\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

n_competencies = length(valid_comp_cols);
correlation_results = table();
correlation_results.Competency = valid_comp_cols';
correlation_results.Correlation = zeros(n_competencies, 1);
correlation_results.PValue = zeros(n_competencies, 1);
correlation_results.HighPerf_Mean = zeros(n_competencies, 1);
correlation_results.LowPerf_Mean = zeros(n_competencies, 1);
correlation_results.Difference = zeros(n_competencies, 1);

% ì„±ê³¼ ìƒìœ„/í•˜ìœ„ ê·¸ë£¹ ë¶„ë¥˜
perf_median = median(valid_performance);
high_perf_idx = valid_performance > perf_median;
low_perf_idx = valid_performance <= perf_median;

for i = 1:n_competencies
    comp_scores = valid_competencies(:, i);
    valid_idx = ~isnan(comp_scores);

    if sum(valid_idx) >= 10
        % ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        [r, p] = corr(comp_scores(valid_idx), valid_performance(valid_idx), ...
                     'Type', 'Spearman');
        correlation_results.Correlation(i) = r;
        correlation_results.PValue(i) = p;

        % ê·¸ë£¹ë³„ í‰ê· 
        correlation_results.HighPerf_Mean(i) = nanmean(comp_scores(high_perf_idx));
        correlation_results.LowPerf_Mean(i) = nanmean(comp_scores(low_perf_idx));
        correlation_results.Difference(i) = correlation_results.HighPerf_Mean(i) - ...
                                           correlation_results.LowPerf_Mean(i);
    end
end

% ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì •ë ¬
correlation_results = sortrows(correlation_results, 'Correlation', 'descend');

% ì–‘ì˜ ìƒê´€ê³„ìˆ˜ë§Œ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ ê³„ì‚°
positive_corr = max(0, correlation_results.Correlation);
weights_raw = abs(positive_corr);
weights_normalized = weights_raw / sum(weights_raw);

correlation_results.Weight = weights_normalized * 100;

%% ========================================================================
%          PART 4: ê³ ë„í™”ëœ ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ë¶„ì„ (í´ë˜ìŠ¤ ë¶ˆê· í˜• ìµœì í™”)
% =========================================================================

fprintf('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
fprintf('      PART 4: ê³ ë„í™”ëœ ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ë¶„ì„ (í´ë˜ìŠ¤ ë¶ˆê· í˜• ìµœì í™”)\n');
fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

%% 4.1 í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ë° ê°œì„ ëœ SMOTE
fprintf('ã€STEP 8ã€‘ ê³ ê¸‰ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% íŠ¹ì„± ë° ë ˆì´ë¸” ì¤€ë¹„
X = table2array(matched_comp);
y = matched_talent_types;
[y_unique, ~, y_encoded] = unique(y);

% í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
class_counts = histcounts(y_encoded, 1:(length(y_unique)+1));
imbalance_ratio = max(class_counts) / min(class_counts);

fprintf('âš  í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„:\n');
fprintf('  â€¢ ë¶ˆê· í˜• ë¹„ìœ¨: %.1f:1\n', imbalance_ratio);
fprintf('  â€¢ í´ë˜ìŠ¤ë³„ ë¶„í¬:\n');
for i = 1:length(y_unique)
    fprintf('    - %-20s: %3dëª… (%5.1f%%)\n', y_unique{i}, class_counts(i), ...
            class_counts(i)/sum(class_counts)*100);
end

% ë°ì´í„° ì •ê·œí™”
X_normalized = normalize(X, 'range');

%% 4.1.1 ê°œì„ ëœ ì ì‘ì  SMOTE êµ¬í˜„
fprintf('\nã€STEP 8-1ã€‘ ì ì‘ì  SMOTE êµ¬í˜„\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ë™ì  ëª©í‘œ ìƒ˜í”Œ ìˆ˜ ì„¤ì •
min_samples = 10;  % ìµœì†Œ ë³´ì¥ ìƒ˜í”Œ
max_samples = round(prctile(class_counts, 75));  % 75 í¼ì„¼íƒ€ì¼ ê¸°ì¤€
target_samples = max(min_samples, min(max_samples, round(median(class_counts))));

fprintf('ëª©í‘œ ìƒ˜í”Œ ìˆ˜: %dëª…/í´ë˜ìŠ¤ (ë²”ìœ„: %d-%d)\n', target_samples, min_samples, max_samples);

% ì ì‘ì  SMOTE ì ìš©
X_balanced = [];
y_balanced = [];

for class = 1:length(y_unique)
    class_idx = find(y_encoded == class);
    X_class = X_normalized(class_idx, :);
    n_samples = length(class_idx);

    if n_samples < target_samples
        % ì†Œìˆ˜ í´ë˜ìŠ¤ - ê°œì„ ëœ ì˜¤ë²„ìƒ˜í”Œë§
        n_synthetic = target_samples - n_samples;

        if n_samples >= 2
            % ì ì‘ì  Kê°’ ì„¤ì •
            k_neighbors = min(max(3, round(sqrt(n_samples))), n_samples-1);

            % ê²½ê³„ì„  ìƒ˜í”Œ ìš°ì„  ì„ íƒì„ ìœ„í•œ ë°€ë„ ê³„ì‚°
            densities = zeros(n_samples, 1);
            for i = 1:n_samples
                distances = sqrt(sum((X_class - X_class(i, :)).^2, 2));
                densities(i) = 1 / (mean(sort(distances(2:min(k_neighbors+1, end)))) + eps);
            end

            % ë‚®ì€ ë°€ë„(ê²½ê³„ì„ ) ìƒ˜í”Œì— ë†’ì€ ê°€ì¤‘ì¹˜
            sample_weights = 1 ./ (densities + eps);
            sample_probs = sample_weights / sum(sample_weights);

            X_synthetic = zeros(n_synthetic, size(X_class, 2));

            for i = 1:n_synthetic
                % ê°€ì¤‘ í™•ë¥ ì— ë”°ë¼ ê¸°ì¤€ ìƒ˜í”Œ ì„ íƒ (í˜¸í™˜ì„± ê°œì„ )
                cumulative_probs = cumsum(sample_probs);
                rand_val = rand();
                base_idx = find(cumulative_probs >= rand_val, 1);
                if isempty(base_idx)
                    base_idx = n_samples;
                end
                base_sample = X_class(base_idx, :);

                % ìµœê·¼ì ‘ ì´ì›ƒ ì°¾ê¸°
                distances = sqrt(sum((X_class - base_sample).^2, 2));
                [~, sorted_idx] = sort(distances);
                neighbor_idx = sorted_idx(randi([2, min(k_neighbors+1, n_samples)]));
                neighbor_sample = X_class(neighbor_idx, :);

                % ì ì‘ì  ë³´ê°„ ê³„ìˆ˜ (ê²½ê³„ì„  ìƒ˜í”Œì¼ìˆ˜ë¡ ë³´ìˆ˜ì )
                density_factor = densities(base_idx) / max(densities);
                lambda = 0.3 + 0.4 * density_factor + 0.3 * rand();  % 0.3-0.7 ë²”ìœ„

                % í•©ì„± ìƒ˜í”Œ ìƒì„± + ì†ŒëŸ‰ ë…¸ì´ì¦ˆ
                noise_level = 0.01 * std(X_class(:));
                X_synthetic(i, :) = base_sample + lambda * (neighbor_sample - base_sample) + ...
                                   noise_level * randn(1, size(X_class, 2));
            end

            X_balanced = [X_balanced; X_class; X_synthetic];
            y_balanced = [y_balanced; repmat(class, n_samples + n_synthetic, 1)];

            fprintf('  %s: %d â†’ %d (ì ì‘ì  SMOTE %dê°œ, K=%d)\n', y_unique{class}, ...
                    n_samples, n_samples + n_synthetic, n_synthetic, k_neighbors);
        else
            % ìƒ˜í”Œì´ 1ê°œë¿ì¸ ê²½ìš° - ë…¸ì´ì¦ˆ ë³€í˜• ë³µì œ
            noise_level = 0.05;
            X_variants = repmat(X_class, target_samples, 1) + ...
                        noise_level * randn(target_samples, size(X_class, 2));
            X_balanced = [X_balanced; X_variants];
            y_balanced = [y_balanced; repmat(class, target_samples, 1)];
            fprintf('  %s: %d â†’ %d (ë…¸ì´ì¦ˆ ë³€í˜• ë³µì œ)\n', y_unique{class}, n_samples, target_samples);
        end
    elseif n_samples > target_samples * 1.5
        % ë‹¤ìˆ˜ í´ë˜ìŠ¤ - ê³„ì¸µí™” ì–¸ë”ìƒ˜í”Œë§
        % ì„±ê³¼ ì ìˆ˜ ê¸°ë°˜ ê³„ì¸µí™”
        class_perf_scores = performance_scores(class_idx);
        if any(class_perf_scores > 0)
            % ì„±ê³¼ ì ìˆ˜ë³„ ê· ë“± ìƒ˜í”Œë§
            [~, ~, perf_bins] = unique(class_perf_scores);
            sample_idx = [];
            samples_per_bin = ceil(target_samples / max(perf_bins));

            for bin = 1:max(perf_bins)
                bin_idx = find(perf_bins == bin);
                if length(bin_idx) <= samples_per_bin
                    sample_idx = [sample_idx; bin_idx];
                else
                    if length(bin_idx) <= samples_per_bin
                        sample_idx = [sample_idx; bin_idx];
                    else
                        rand_perm = randperm(length(bin_idx));
                        sample_idx = [sample_idx; bin_idx(rand_perm(1:samples_per_bin))];
                    end
                end
            end
            sample_idx = sample_idx(1:min(target_samples, end));
        else
            rand_perm = randperm(n_samples);
            sample_idx = rand_perm(1:target_samples);
        end

        X_balanced = [X_balanced; X_class(sample_idx, :)];
        y_balanced = [y_balanced; repmat(class, length(sample_idx), 1)];
        fprintf('  %s: %d â†’ %d (ê³„ì¸µí™” ì–¸ë”ìƒ˜í”Œë§)\n', y_unique{class}, n_samples, length(sample_idx));
    else
        % ì ì ˆí•œ ìˆ˜ì¤€ - ê·¸ëŒ€ë¡œ ì‚¬ìš©
        X_balanced = [X_balanced; X_class];
        y_balanced = [y_balanced; repmat(class, n_samples, 1)];
        fprintf('  %s: %d (ìœ ì§€)\n', y_unique{class}, n_samples);
    end
end

fprintf('ê· í˜•í™” ì™„ë£Œ: %d â†’ %d ìƒ˜í”Œ\n', length(y_encoded), length(y_balanced));

%% 4.2 êµì°¨ê²€ì¦ ê¸°ë°˜ ëª¨ë¸ ìµœì í™”
fprintf('\nã€STEP 9ã€‘ êµì°¨ê²€ì¦ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% ì›ë³¸ ë°ì´í„°ë¥¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í•  (ìˆ˜ë™ ê³„ì¸µí™” ë¶„í• )
test_ratio = 0.2;
test_indices = [];
for class = 1:length(y_unique)
    class_indices = find(y_encoded == class);
    n_test = max(1, round(length(class_indices) * test_ratio));
    rand_perm = randperm(length(class_indices));
    test_indices = [test_indices; class_indices(rand_perm(1:n_test))];
end
train_indices = setdiff(1:length(y_encoded), test_indices);

X_test = X_normalized(test_indices, :);
y_test = y_encoded(test_indices);

% ê· í˜•í™”ëœ ë°ì´í„°ë¥¼ í›ˆë ¨ìš©ìœ¼ë¡œ ì‚¬ìš©
X_train = X_balanced;
y_train = y_balanced;

fprintf('â–¶ í›ˆë ¨ ë°ì´í„°: %dëª… (ê· í˜•í™”ë¨)\n', length(y_train));
fprintf('â–¶ í…ŒìŠ¤íŠ¸ ë°ì´í„°: %dëª… (ì›ë³¸)\n', length(y_test));

% 5-Fold êµì°¨ê²€ì¦ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ìˆ˜ë™ êµ¬í˜„)
cv_folds = 5;
n_train = length(y_train);
fold_size = floor(n_train / cv_folds);
cv_indices = cell(cv_folds, 1);
rand_perm = randperm(n_train);
for fold = 1:cv_folds
    start_idx = (fold-1) * fold_size + 1;
    if fold == cv_folds
        end_idx = n_train;
    else
        end_idx = fold * fold_size;
    end
    cv_indices{fold} = rand_perm(start_idx:end_idx);
end

% Random Forest íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
rf_params = struct();
rf_params.n_trees = [50, 100, 150, 200];
rf_params.min_leaf = [1, 2, 3, 5];
rf_params.max_splits = [10, 20, 50];

best_rf_score = 0;
best_rf_params = struct();

fprintf('Random Forest í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...\n');
param_count = 0;
total_params = length(rf_params.n_trees) * length(rf_params.min_leaf) * length(rf_params.max_splits);

for n_trees = rf_params.n_trees
    for min_leaf = rf_params.min_leaf
        for max_splits = rf_params.max_splits
            param_count = param_count + 1;

            % êµì°¨ê²€ì¦ í‰ê°€
            cv_scores = zeros(cv_folds, 1);
            for fold = 1:cv_folds
                val_indices = cv_indices{fold};
                train_indices_fold = setdiff(1:n_train, val_indices);

                X_train_fold = X_train(train_indices_fold, :);
                y_train_fold = y_train(train_indices_fold);
                X_val_fold = X_train(val_indices, :);
                y_val_fold = y_train(val_indices);

                % ëª¨ë¸ í•™ìŠµ
                model = TreeBagger(n_trees, X_train_fold, y_train_fold, ...
                    'Method', 'classification', ...
                    'MinLeafSize', min_leaf, ...
                    'MaxNumSplits', max_splits);

                % ì˜ˆì¸¡ ë° ê· í˜• ì •í™•ë„ ê³„ì‚°
                y_pred = cellfun(@str2double, predict(model, X_val_fold));

                % í´ë˜ìŠ¤ë³„ ì¬í˜„ìœ¨ ê³„ì‚° (ê· í˜• ì •í™•ë„)
                unique_classes = unique(y_val_fold);
                class_recalls = zeros(length(unique_classes), 1);
                for c = 1:length(unique_classes)
                    class_mask = y_val_fold == unique_classes(c);
                    if sum(class_mask) > 0
                        class_recalls(c) = sum(y_pred(class_mask) == unique_classes(c)) / sum(class_mask);
                    end
                end
                cv_scores(fold) = mean(class_recalls);  % ê· í˜• ì •í™•ë„
            end

            mean_score = mean(cv_scores);
            if mean_score > best_rf_score
                best_rf_score = mean_score;
                best_rf_params.n_trees = n_trees;
                best_rf_params.min_leaf = min_leaf;
                best_rf_params.max_splits = max_splits;
            end

            if mod(param_count, 10) == 0 || param_count == total_params
                fprintf('  ì§„í–‰ë¥ : %d/%d (%.1f%%), í˜„ì¬ ìµœê³ : %.4f\n', ...
                        param_count, total_params, param_count/total_params*100, best_rf_score);
            end
        end
    end
end

fprintf('ìµœì  RF íŒŒë¼ë¯¸í„°: Trees=%d, MinLeaf=%d, MaxSplits=%d, CVì ìˆ˜=%.4f\n', ...
        best_rf_params.n_trees, best_rf_params.min_leaf, best_rf_params.max_splits, best_rf_score);

%% 4.3 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±
fprintf('\nã€STEP 10ã€‘ ë‹¤ì¤‘ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

rng(42);  % ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ

% 1. ìµœì í™”ëœ Random Forest
fprintf('1. ìµœì í™”ëœ Random Forest í•™ìŠµ ì¤‘...\n');
rf_model = TreeBagger(best_rf_params.n_trees, X_train, y_train, ...
    'Method', 'classification', ...
    'MinLeafSize', best_rf_params.min_leaf, ...
    'MaxNumSplits', best_rf_params.max_splits, ...
    'OOBPredictorImportance', 'on', ...
    'PredictorNames', valid_comp_cols);

% 2. Cost-sensitive Gradient Boosting
fprintf('2. Cost-sensitive Gradient Boosting í•™ìŠµ ì¤‘...\n');
% í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
unique_train_classes = unique(y_train);
class_costs = zeros(length(unique_train_classes), length(unique_train_classes));
for i = 1:length(unique_train_classes)
    for j = 1:length(unique_train_classes)
        if i ~= j
            % ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜¤ë¶„ë¥˜ì— ë” í° ë¹„ìš©
            class_i_count = sum(y_train == unique_train_classes(i));
            total_samples = length(y_train);
            cost_weight = total_samples / (length(unique_train_classes) * class_i_count);
            class_costs(i, j) = cost_weight;
        end
    end
end

gb_model = fitcensemble(X_train, y_train, ...
    'Method', 'AdaBoostM2', ...
    'NumLearningCycles', 100, ...
    'LearnRate', 0.1, ...
    'Learners', templateTree('MaxNumSplits', 20, 'MinLeafSize', 5), ...
    'Cost', class_costs);

% 3. í´ë˜ìŠ¤ë³„ ì „ë¬¸ ë¶„ë¥˜ê¸° (One-vs-Rest)
fprintf('3. í´ë˜ìŠ¤ë³„ ì „ë¬¸ ë¶„ë¥˜ê¸° í•™ìŠµ ì¤‘...\n');
class_experts = cell(length(y_unique), 1);
expert_scores = zeros(length(y_unique), 1);

for class = 1:length(y_unique)
    if sum(y_train == class) >= 5  % ìµœì†Œ 5ê°œ ìƒ˜í”Œ í•„ìš”
        y_binary = double(y_train == class);

        % ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ SMOTE ì¶”ê°€ ì ìš©
        pos_idx = find(y_binary == 1);
        neg_idx = find(y_binary == 0);

        if length(pos_idx) < length(neg_idx) / 2
            % ì–‘ì„± í´ë˜ìŠ¤ ì¶”ê°€ ì¦ê°•
            n_synthetic = min(length(neg_idx) - length(pos_idx), length(pos_idx));
            X_pos = X_train(pos_idx, :);

            for i = 1:n_synthetic
                base_idx = randi(length(pos_idx));
                if length(pos_idx) > 1
                    neighbor_idx = randi(length(pos_idx));
                    while neighbor_idx == base_idx
                        neighbor_idx = randi(length(pos_idx));
                    end
                    lambda = rand();
                    synthetic_sample = X_pos(base_idx, :) + lambda * (X_pos(neighbor_idx, :) - X_pos(base_idx, :));
                    X_train = [X_train; synthetic_sample];
                    y_binary = [y_binary; 1];
                end
            end
        end

        class_experts{class} = fitcensemble(X_train(1:length(y_train), :), y_binary(1:length(y_train)), ...
            'Method', 'RUSBoost', ...
            'NumLearningCycles', 50, ...
            'Learners', templateTree('MaxNumSplits', 10));

        % êµì°¨ê²€ì¦ í‰ê°€ (3-fold ìˆ˜ë™ êµ¬í˜„)
        y_binary_subset = y_binary(1:length(y_train));
        n_binary = length(y_binary_subset);
        fold_size_expert = floor(n_binary / 3);
        expert_cv_scores = zeros(3, 1);
        rand_perm_expert = randperm(n_binary);

        for fold = 1:3
            start_idx = (fold-1) * fold_size_expert + 1;
            if fold == 3
                end_idx = n_binary;
            else
                end_idx = fold * fold_size_expert;
            end
            test_idx_expert = rand_perm_expert(start_idx:end_idx);
            train_idx_expert = setdiff(1:n_binary, test_idx_expert);

            if length(test_idx_expert) > 0 && length(train_idx_expert) > 0
                y_pred_expert = predict(class_experts{class}, X_train(test_idx_expert, :));
                y_true_expert = y_binary_subset(test_idx_expert);
                expert_cv_scores(fold) = sum(y_pred_expert == y_true_expert) / length(y_true_expert);
            end
        end
        expert_scores(class) = mean(expert_cv_scores);

        fprintf('  %s ì „ë¬¸ê°€: CV ì •í™•ë„ %.3f\n', y_unique{class}, expert_scores(class));
    end
end

%% 4.4 ì•™ìƒë¸” ì˜ˆì¸¡ ë° í‰ê°€
fprintf('\nã€STEP 11ã€‘ ì•™ìƒë¸” ì˜ˆì¸¡ ë° í‰ê°€\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% Random Forest ì˜ˆì¸¡
[y_pred_rf_cell, rf_scores] = predict(rf_model, X_test);
y_pred_rf = cellfun(@str2double, y_pred_rf_cell);
% TreeBagger ê²°ê³¼ ì²˜ë¦¬ (MATLAB ë²„ì „ í˜¸í™˜ì„±)
if iscell(rf_scores)
    rf_probs = cell2mat(rf_scores);
else
    rf_probs = rf_scores;
end

% Gradient Boosting ì˜ˆì¸¡
[y_pred_gb, gb_scores] = predict(gb_model, X_test);
gb_probs = gb_scores;

% í´ë˜ìŠ¤ ì „ë¬¸ê°€ ì˜ˆì¸¡
expert_probs = zeros(length(y_test), length(y_unique));
for class = 1:length(y_unique)
    if ~isempty(class_experts{class})
        [~, scores] = predict(class_experts{class}, X_test);
        if size(scores, 2) >= 2
            expert_probs(:, class) = scores(:, 2);
        end
    end
end

% ê°€ì¤‘ ì•™ìƒë¸” (ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)
model_weights = [0.4, 0.3, 0.3];  % RF, GB, Expert ê°€ì¤‘ì¹˜
ensemble_probs = model_weights(1) * rf_probs + model_weights(2) * gb_probs + ...
                model_weights(3) * expert_probs;

% í™•ë¥  ì •ê·œí™”
ensemble_probs = ensemble_probs ./ sum(ensemble_probs, 2);
[~, y_pred_ensemble] = max(ensemble_probs, [], 2);

% ê°œë³„ ëª¨ë¸ ì •í™•ë„
rf_accuracy = sum(y_pred_rf == y_test) / length(y_test);
gb_accuracy = sum(y_pred_gb == y_test) / length(y_test);
ensemble_accuracy = sum(y_pred_ensemble == y_test) / length(y_test);

fprintf('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:\n');
fprintf('  â€¢ Random Forest: %.4f\n', rf_accuracy);
fprintf('  â€¢ Gradient Boosting: %.4f\n', gb_accuracy);
fprintf('  â€¢ ê°€ì¤‘ ì•™ìƒë¸”: %.4f\n', ensemble_accuracy);

%% 4.5 ê³ ê¸‰ ì„±ëŠ¥ í‰ê°€
fprintf('\nã€STEP 12ã€‘ ê³ ê¸‰ ì„±ëŠ¥ í‰ê°€\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% Confusion Matrix
conf_ensemble = confusionmat(y_test, y_pred_ensemble);

% í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
n_classes = length(y_unique);
class_metrics = table();
class_metrics.TalentType = y_unique;
class_metrics.Precision = zeros(n_classes, 1);
class_metrics.Recall = zeros(n_classes, 1);
class_metrics.F1Score = zeros(n_classes, 1);
class_metrics.Support = zeros(n_classes, 1);
class_metrics.Confidence = zeros(n_classes, 1);

for i = 1:n_classes
    tp = conf_ensemble(i, i);
    fp = sum(conf_ensemble(:, i)) - tp;
    fn = sum(conf_ensemble(i, :)) - tp;

    class_metrics.Precision(i) = tp / (tp + fp + eps);
    class_metrics.Recall(i) = tp / (tp + fn + eps);
    class_metrics.F1Score(i) = 2 * (class_metrics.Precision(i) * class_metrics.Recall(i)) / ...
                              (class_metrics.Precision(i) + class_metrics.Recall(i) + eps);
    class_metrics.Support(i) = sum(y_test == i);

    % ì˜ˆì¸¡ í™•ì‹ ë„ (í•´ë‹¹ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ëœ ìƒ˜í”Œë“¤ì˜ í‰ê·  í™•ë¥ )
    pred_mask = y_pred_ensemble == i;
    if sum(pred_mask) > 0
        class_metrics.Confidence(i) = mean(ensemble_probs(pred_mask, i));
    end
end

% ê· í˜• ì •í™•ë„ ë° ê¸°íƒ€ ë©”íŠ¸ë¦­
balanced_accuracy = mean(class_metrics.Recall);
macro_f1 = mean(class_metrics.F1Score);
weighted_f1 = sum(class_metrics.F1Score .* class_metrics.Support) / sum(class_metrics.Support);

% Matthews ìƒê´€ê³„ìˆ˜ ê³„ì‚°
mcc_numerator = 0;
mcc_denominator = 0;
for i = 1:n_classes
    for j = 1:n_classes
        for k = 1:n_classes
            mcc_numerator = mcc_numerator + conf_ensemble(i,i) * conf_ensemble(j,k) - ...
                           conf_ensemble(i,k) * conf_ensemble(k,i);
        end
    end
end

sum_pred = sum(conf_ensemble, 1);
sum_true = sum(conf_ensemble, 2)';
mcc_denominator = sqrt(sum(sum_pred.^2) - sum(sum_pred)^2) * ...
                 sqrt(sum(sum_true.^2) - sum(sum_true)^2);
mcc = mcc_numerator / (mcc_denominator + eps);

fprintf('\nì¢…í•© ì„±ëŠ¥ ì§€í‘œ:\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');
fprintf('  â€¢ ì •í™•ë„ (Accuracy): %.4f\n', ensemble_accuracy);
fprintf('  â€¢ ê· í˜• ì •í™•ë„ (Balanced Accuracy): %.4f\n', balanced_accuracy);
fprintf('  â€¢ Macro F1-Score: %.4f\n', macro_f1);
fprintf('  â€¢ Weighted F1-Score: %.4f\n', weighted_f1);
fprintf('  â€¢ Matthews ìƒê´€ê³„ìˆ˜ (MCC): %.4f\n', mcc);

fprintf('\ní´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥:\n');
fprintf('%-20s | Prec. | Recall | F1    | Conf. | Support\n', 'ì¸ì¬ìœ í˜•');
fprintf('%s\n', repmat('-', 65, 1));

for i = 1:height(class_metrics)
    fprintf('%-20s | %5.3f | %6.3f | %5.3f | %5.3f | %7d\n', ...
        class_metrics.TalentType{i}, ...
        class_metrics.Precision(i), ...
        class_metrics.Recall(i), ...
        class_metrics.F1Score(i), ...
        class_metrics.Confidence(i), ...
        class_metrics.Support(i));
end

%% 4.6 Feature Importance ë¶„ì„
fprintf('\nã€STEP 13ã€‘ ì•™ìƒë¸” Feature Importance\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% Random Forest importance
rf_importance = rf_model.OOBPermutedPredictorDeltaError;
rf_importance_norm = rf_importance / sum(rf_importance);

% Gradient Boosting importance
gb_importance = predictorImportance(gb_model);
gb_importance_norm = gb_importance / sum(gb_importance);

% ìƒê´€ ê¸°ë°˜ ê°€ì¤‘ì¹˜ì™€ ê²°í•©
final_importance = (0.4 * rf_importance_norm + 0.3 * gb_importance_norm + 0.3 * weights_normalized');
final_importance = final_importance / sum(final_importance);

% Feature Importance í…Œì´ë¸” (ì°¨ì› ë§ì¶¤)
importance_table = table();
importance_table.Competency = valid_comp_cols';

% ëª¨ë“  ë³€ìˆ˜ë¥¼ ì—´ ë²¡í„°ë¡œ ë³€í™˜
rf_importance_norm = rf_importance_norm(:);
gb_importance_norm = gb_importance_norm(:);
weights_normalized = weights_normalized(:);
final_importance = final_importance(:);

% ê¸¸ì´ í™•ì¸ ë° ì¡°ì •
n_features = length(valid_comp_cols);
if length(rf_importance_norm) ~= n_features
    rf_importance_norm = rf_importance_norm(1:min(end, n_features));
    if length(rf_importance_norm) < n_features
        rf_importance_norm = [rf_importance_norm; zeros(n_features - length(rf_importance_norm), 1)];
    end
end
if length(gb_importance_norm) ~= n_features
    gb_importance_norm = gb_importance_norm(1:min(end, n_features));
    if length(gb_importance_norm) < n_features
        gb_importance_norm = [gb_importance_norm; zeros(n_features - length(gb_importance_norm), 1)];
    end
end
if length(weights_normalized) ~= n_features
    weights_normalized = weights_normalized(1:min(end, n_features));
    if length(weights_normalized) < n_features
        weights_normalized = [weights_normalized; zeros(n_features - length(weights_normalized), 1)];
    end
end
if length(final_importance) ~= n_features
    final_importance = final_importance(1:min(end, n_features));
    if length(final_importance) < n_features
        final_importance = [final_importance; zeros(n_features - length(final_importance), 1)];
    end
end

importance_table.RF_Importance = rf_importance_norm * 100;
importance_table.GB_Importance = gb_importance_norm * 100;
importance_table.Correlation_Weight = weights_normalized * 100;
importance_table.Final_Importance = final_importance * 100;

importance_table = sortrows(importance_table, 'Final_Importance', 'descend');

fprintf('\nìµœì¢… Feature Importance (ìƒìœ„ 10ê°œ):\n');
fprintf('%-30s | RF(%) | GB(%) | Corr(%) | Final(%%)\n', 'ì—­ëŸ‰');
fprintf('%s\n', repmat('-', 70, 1));

for i = 1:min(10, height(importance_table))
    fprintf('%-30s | %5.2f | %5.2f | %7.2f | %7.2f\n', ...
        importance_table.Competency{i}, ...
        importance_table.RF_Importance(i), ...
        importance_table.GB_Importance(i), ...
        importance_table.Correlation_Weight(i), ...
        importance_table.Final_Importance(i));
end

%% ========================================================================
%                          PART 5: ê²°ê³¼ ì €ì¥ ë° ë³´ê³ ì„œ
% =========================================================================

fprintf('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
fprintf('              PART 5: ê²°ê³¼ ì €ì¥ ë° ìµœì¢… ë³´ê³ ì„œ\n');
fprintf('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

%% 5.1 ê²°ê³¼ ì €ì¥
fprintf('ã€STEP 14ã€‘ ë¶„ì„ ê²°ê³¼ ì €ì¥\n');
fprintf('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

% MATLAB íŒŒì¼ ì €ì¥
analysis_results = struct();
analysis_results.profile_stats = profile_stats;
analysis_results.correlation_results = correlation_results;
analysis_results.importance_table = importance_table;
analysis_results.class_metrics = class_metrics;
analysis_results.models = struct('rf', rf_model, 'gb', gb_model, 'experts', {class_experts});
analysis_results.performance = struct('rf', rf_accuracy, 'gb', gb_accuracy, ...
                                    'ensemble', ensemble_accuracy, 'balanced', balanced_accuracy, ...
                                    'macro_f1', macro_f1, 'mcc', mcc);
analysis_results.ensemble_probs = ensemble_probs;
analysis_results.config = config;

save('talent_analysis_v3_complete.mat', 'analysis_results');
fprintf('âœ“ MATLAB íŒŒì¼ ì €ì¥: talent_analysis_v3_complete.mat\n');

% Excel íŒŒì¼ ì €ì¥
try
    % Sheet 1: ì¸ì¬ìœ í˜• í”„ë¡œíŒŒì¼
    writetable(profile_stats, 'talent_analysis_v3_report.xlsx', ...
              'Sheet', 'TalentProfiles');

    % Sheet 2: ìƒê´€ë¶„ì„ ê²°ê³¼
    writetable(correlation_results(1:min(30, height(correlation_results)), :), ...
              'talent_analysis_v3_report.xlsx', 'Sheet', 'CorrelationAnalysis');

    % Sheet 3: Feature Importance
    writetable(importance_table(1:min(30, height(importance_table)), :), ...
              'talent_analysis_v3_report.xlsx', 'Sheet', 'FeatureImportance');

    % Sheet 4: ëª¨ë¸ ì„±ëŠ¥
    model_performance = table();
    model_performance.Model = {'Random Forest'; 'Gradient Boosting'; 'Weighted Ensemble'};
    model_performance.Accuracy = [rf_accuracy; gb_accuracy; ensemble_accuracy];
    model_performance.Balanced_Accuracy = [NaN; NaN; balanced_accuracy];
    model_performance.Macro_F1 = [NaN; NaN; macro_f1];
    model_performance.MCC = [NaN; NaN; mcc];

    writetable(model_performance, 'talent_analysis_v3_report.xlsx', ...
              'Sheet', 'ModelPerformance');

    % Sheet 5: í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
    writetable(class_metrics, 'talent_analysis_v3_report.xlsx', ...
              'Sheet', 'ClassPerformance');

    fprintf('âœ“ Excel íŒŒì¼ ì €ì¥: talent_analysis_v3_report.xlsx\n');
catch
    fprintf('âš  Excel ì €ì¥ ì‹¤íŒ¨ (íŒŒì¼ì´ ì—´ë ¤ìˆì„ ìˆ˜ ìˆìŒ)\n');
end

%% 5.2 ìµœì¢… ë³´ê³ ì„œ
fprintf('\n%s\n', repmat('â•', 80, 1));
fprintf('                     ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ v3.0\n');
fprintf('%s\n', repmat('â•', 80, 1));

fprintf('\nğŸ“Š ë°ì´í„° ìš”ì•½:\n');
fprintf('  â€¢ ë¶„ì„ ëŒ€ìƒ: %dëª…\n', length(matched_ids));
fprintf('  â€¢ ì¸ì¬ìœ í˜•: %dê°œ\n', n_types);
fprintf('  â€¢ ì—­ëŸ‰í•­ëª©: %dê°œ\n', length(valid_comp_cols));
fprintf('  â€¢ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: %.1f:1\n', imbalance_ratio);

fprintf('\nğŸ”§ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ë°©ë²•:\n');
fprintf('  â€¢ ì ì‘ì  SMOTE (ê²½ê³„ì„  ìƒ˜í”Œ ìš°ì„ , ë™ì  Kê°’)\n');
fprintf('  â€¢ ê³„ì¸µí™” ì–¸ë”ìƒ˜í”Œë§ (ì„±ê³¼ ê¸°ë°˜)\n');
fprintf('  â€¢ ë…¸ì´ì¦ˆ ì¶”ê°€ ë° ë°€ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜\n');
fprintf('  â€¢ ë‹¤ì¤‘ ì•™ìƒë¸” (RF + GB + ì „ë¬¸ê°€ ëª¨ë¸)\n');

fprintf('\nğŸ¯ ì£¼ìš” ë°œê²¬ì‚¬í•­:\n');
fprintf('  1. ìµœê³  ì„±ê³¼ ì¸ì¬ìœ í˜•: %s\n', ...
    profile_stats.TalentType{profile_stats.PerformanceRank == max(profile_stats.PerformanceRank)});

fprintf('  2. í•µì‹¬ ì˜ˆì¸¡ ì—­ëŸ‰ Top 3:\n');
for i = 1:min(3, height(importance_table))
    fprintf('     - %s (%.2f%%)\n', importance_table.Competency{i}, ...
            importance_table.Final_Importance(i));
end

fprintf('\nğŸ¤– ëª¨ë¸ ì„±ëŠ¥ (v3.0 ê°œì„ ):\n');
fprintf('  â€¢ ì „ì²´ ì •í™•ë„: %.2f%%\n', ensemble_accuracy * 100);
fprintf('  â€¢ ê· í˜• ì •í™•ë„: %.2f%% (ì†Œìˆ˜ í´ë˜ìŠ¤ ê³ ë ¤)\n', balanced_accuracy * 100);
fprintf('  â€¢ Macro F1-Score: %.2f%%\n', macro_f1 * 100);
fprintf('  â€¢ Matthews ìƒê´€ê³„ìˆ˜: %.3f\n', mcc);

fprintf('\nğŸ“ˆ ì„±ëŠ¥ ê°œì„  íš¨ê³¼:\n');
if balanced_accuracy > 0.7
    fprintf('  â€¢ ìš°ìˆ˜: ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ ìˆ˜ì¤€\n');
elseif balanced_accuracy > 0.5
    fprintf('  â€¢ ì–‘í˜¸: ë³´ì¡° ë„êµ¬ë¡œ í™œìš© ê°€ëŠ¥\n');
else
    fprintf('  â€¢ ê°œì„  í•„ìš”: ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ê¶Œì¥\n');
end

fprintf('\nâœ¨ ê¶Œì¥ì‚¬í•­:\n');
fprintf('  1. ìƒìœ„ 5ê°œ ì—­ëŸ‰ (%s ë“±)ìœ¼ë¡œ 1ì°¨ ìŠ¤í¬ë¦¬ë‹\n', importance_table.Competency{1});
fprintf('  2. ì˜ˆì¸¡ í™•ì‹ ë„ %.2f ì´ìƒì¼ ë•Œ ë†’ì€ ì‹ ë¢°ë„\n', mean(class_metrics.Confidence));
fprintf('  3. ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ í›„ ì¬í•™ìŠµ\n');
fprintf('  4. 3ê°œì›”ë§ˆë‹¤ ëª¨ë¸ ì¬í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ ìœ ì§€\n');

fprintf('\nğŸ“‹ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:\n');
fprintf('  â€¢ SMOTE í•©ì„± ìƒ˜í”Œ: %dê°œ\n', length(y_balanced) - length(y_encoded));
fprintf('  â€¢ êµì°¨ê²€ì¦ fold: 5-fold\n');
fprintf('  â€¢ ì•™ìƒë¸” êµ¬ì„±: RF(40%%) + GB(30%%) + Expert(30%%)\n');
fprintf('  â€¢ í•˜ì´í¼íŒŒë¼ë¯¸í„°: Trees=%d, MinLeaf=%d, MaxSplits=%d\n', ...
         best_rf_params.n_trees, best_rf_params.min_leaf, best_rf_params.max_splits);

fprintf('\n%s\n', repmat('â•', 80, 1));
fprintf('               ë¶„ì„ ì™„ë£Œ - %s\n', datestr(now, 'yyyy-mm-dd HH:MM:SS'));
fprintf('%s\n', repmat('â•', 80, 1));

%% ì¶”ê°€ ì‹œê°í™”
figure('Position', [100, 100, 1400, 1000], 'Color', 'white');

% Subplot 1: í´ë˜ìŠ¤ ë¶„í¬ (ì›ë³¸ vs ê· í˜•í™”)
subplot(2, 3, 1);
original_dist = histcounts(y_encoded, 1:(length(y_unique)+1));
balanced_dist = histcounts(y_balanced, 1:(length(y_unique)+1));
bar_data = [original_dist; balanced_dist]';
bar(bar_data);
set(gca, 'XTickLabel', y_unique, 'XTickLabelRotation', 45);
ylabel('ìƒ˜í”Œ ìˆ˜');
title('í´ë˜ìŠ¤ ë¶„í¬ ë³€í™”');
legend('ì›ë³¸', 'ê· í˜•í™”', 'Location', 'best');
grid on;

% Subplot 2: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
subplot(2, 3, 2);
model_names = {'RF', 'GB', 'Ensemble'};
accuracies = [rf_accuracy, gb_accuracy, ensemble_accuracy];
bar(accuracies, 'FaceColor', [0.3, 0.6, 0.9]);
set(gca, 'XTickLabel', model_names);
ylabel('ì •í™•ë„');
title('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ');
ylim([0, 1]);
grid on;
for i = 1:length(accuracies)
    text(i, accuracies(i) + 0.02, sprintf('%.3f', accuracies(i)), ...
         'HorizontalAlignment', 'center');
end

% Subplot 3: í´ë˜ìŠ¤ë³„ F1-Score
subplot(2, 3, 3);
bar(class_metrics.F1Score, 'FaceColor', [0.9, 0.3, 0.3]);
set(gca, 'XTickLabel', class_metrics.TalentType, 'XTickLabelRotation', 45);
ylabel('F1-Score');
title('í´ë˜ìŠ¤ë³„ F1-Score');
grid on;

% Subplot 4: Feature Importance Top 10
subplot(2, 3, 4:6);
top_n = min(10, height(importance_table));
bar_data = [importance_table.RF_Importance(1:top_n), ...
           importance_table.GB_Importance(1:top_n), ...
           importance_table.Final_Importance(1:top_n)];
bar(bar_data);
set(gca, 'XTickLabel', importance_table.Competency(1:top_n), 'XTickLabelRotation', 45);
ylabel('ì¤‘ìš”ë„ (%)');
title('Feature Importance ë¹„êµ (ìƒìœ„ 10ê°œ)');
legend('Random Forest', 'Gradient Boosting', 'Final Ensemble', 'Location', 'northeast');
grid on;

sgtitle('ì¸ì¬ìœ í˜• ì˜ˆì¸¡ ëª¨ë¸ v3.0 - ì¢…í•© ë¶„ì„ ê²°ê³¼', 'FontSize', 16, 'FontWeight', 'bold');

fprintf('\nğŸ“ˆ ì‹œê°í™” ì™„ë£Œ: í´ë˜ìŠ¤ ë¶„í¬, ëª¨ë¸ ì„±ëŠ¥, Feature Importance ì°¨íŠ¸ ìƒì„±\n');
